{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "    - Done\n",
    "* Apply a distortion correction to raw images.\n",
    "    - Done\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "    - Done\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# need to find the transform from real world object coords to image coords\n",
    "def findObjectPtsAndImgPts(pathToCalibImgs='./camera_cal/calibration*.jpg'\n",
    "                              , shapeOfBoard=[9,6], verbose=False):\n",
    "    \"\"\"\n",
    "    pathToCalibImgs: the regex to the calibration images that is passed to glob\n",
    "    shapeOfBoard: the x and y dimensions of the chessboard used for calibration\n",
    "    verbos: show the images and print data\n",
    "    \n",
    "    returns\n",
    "    objPoints\n",
    "    imgPoints\n",
    "    \"\"\"\n",
    "    %matplotlib inline\n",
    "\n",
    "    images = glob.glob(pathToCalibImgs)\n",
    "    count = 0\n",
    "\n",
    "    objPoints = [] # 3d points \n",
    "    imgPoints = [] # 2d points\n",
    "\n",
    "    # we know the objects points because its a calibration image\n",
    "    nx = shapeOfBoard[0] # interior chessboard corners in the x dim\n",
    "    ny = shapeOfBoard[1] # interior chessboard corners in the y dim\n",
    "    objPts = np.zeros((nx*ny, 3), np.float32)\n",
    "    objPts[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    for fileName in images:\n",
    "        img = cv2.imread(fileName)\n",
    "        # cv2 fn takes gray space img\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        # if the function finds chessboard corners, append known object points and found image points\n",
    "        if ret:\n",
    "            imgPoints.append(corners)\n",
    "            objPoints.append(objPts)\n",
    "            count = count + 1\n",
    "\n",
    "            # visualize\n",
    "            if verbose:\n",
    "                cornersImg = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "                plt.figure()\n",
    "                plt.title(fileName)\n",
    "                plt.imshow(cornersImg)\n",
    "            \n",
    "    if verbose:\n",
    "        print('percentage found:', count/np.shape(images)[0] * 100)\n",
    "        \n",
    "    return objPoints, imgPoints\n",
    "        \n",
    "def calibrateCamera(objPoints, imgPoints, pathToImg='./camera_cal/calibration2.jpg'\n",
    "                    , verbose=False):\n",
    "    \"\"\"\n",
    "    wrapper for cv2.calibrateCamera, optional print images\n",
    "    \"\"\"\n",
    "    \n",
    "    %matplotlib inline\n",
    "\n",
    "    img = cv2.imread(pathToImg)\n",
    "\n",
    "    # cameraMtx, camera matrix that discribes the mapping of pinhole camera to convex camera pts\n",
    "    # distortCoeffs, the tangential and radial distortion coefficients\n",
    "    # rotVect, rotational vectors to get camera attitude\n",
    "    # transVects, translational vecotrs to get camera position\n",
    "    ret, cameraMtx, distortCoeffs, rotVects, transVects = \\\n",
    "        cv2.calibrateCamera(objPoints, imgPoints, img.shape[1::-1], None, None)\n",
    "\n",
    "    if verbose:\n",
    "        undistImg = cv2.undistort(img, cameraMtx, distortCoeffs, None, cameraMtx)\n",
    "\n",
    "        # visualize\n",
    "        plt.figure()\n",
    "        plt.title('Undistorted image: \\'%s\\'' %pathToImg)\n",
    "        plt.imshow(undistImg)\n",
    "        \n",
    "    return ret, cameraMtx, distortCoeffs, rotVects, transVects\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def roiMask(img, verbose=False):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "      cannyImg, the result from performCannyEdgeDetection()\n",
    "      show, plot the roi masked image\n",
    "    outputs:\n",
    "      roiImg, the resultant image\n",
    "    \"\"\"\n",
    "#     img = cv2.imread(imagePath)\n",
    "    xSize = img.shape[1]\n",
    "    ySize = img.shape[0]\n",
    "    \n",
    "#     # mask inside of lane\n",
    "#     roiInside = np.array([[(0,ySize),(xSize *(1/4), ySize),(xSize / 2, ySize * (2 / 3)),(xSize * (3/4),ySize),(xSize,ySize),(xSize,0),(0,0)]], dtype=np.int32)\n",
    "#     roiImg = region_of_interest(img, roiInside)\n",
    "    \n",
    "    # mask outside of lane\n",
    "    roi = np.array([[(0, ySize), (xSize, ySize), (xSize / 2 + (xSize / 20), ySize / 2 + (ySize / 10)), (xSize / 2 - (xSize / 20), ySize / 2 + (ySize / 10))]], dtype=np.int32)\n",
    "    roiImg = region_of_interest(img, roi) # create empty mask, fill polygon in mask, bitwise and the mask and img\n",
    "    \n",
    "    if verbose:\n",
    "        roiImage = plt.figure()\n",
    "        plt.title('ROI Mask')\n",
    "        plt.imshow(roiImg, cmap='gray')\n",
    "        roiImage.savefig('./roiImg.jpg')\n",
    "        \n",
    "    return roiImg\n",
    "    \n",
    "def createBinary(imagePath, colorThresh=(170,255), xGradientThresh=(20,100)\n",
    "                        , verbose=True):\n",
    "    image = cv2.imread(imagePath)\n",
    "    s_thresh = colorThresh # color channel threshhold\n",
    "    sx_thresh = xGradientThresh # x gradient thresh hold\n",
    "\n",
    "    img = np.copy(image)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "    # combine both thresholds into a binary\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "\n",
    "    # Plot the result\n",
    "    if verbose:\n",
    "        f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "\n",
    "        ax1.imshow(image)\n",
    "        ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "        ax2.imshow(color_binary)\n",
    "        ax2.set_title('Sobel X, and Color channel ', fontsize=40)\n",
    "        plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "        ax3.imshow(combined_binary, cmap='gray')\n",
    "        \n",
    "    return combined_binary\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def findHoughLines(roiImg, show=False, rho=1, theta=(np.pi/360), threshold=15, min_line_len=12, max_line_gap=10):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      roiImg, the result from performROIMasking()\n",
    "      rho, the length resolution in a mesh unit [pixel]\n",
    "      theta, the angular resolution of the mesh [radians]\n",
    "      threshold, min number of votes for line detection\n",
    "      min_line_len, [pixels]\n",
    "      max_line_gap, [pixels]\n",
    "      show, plot the hough line image\n",
    "    outputs:\n",
    "      houghImg, the resultant image\n",
    "      lines, the resultant hough lines\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(roiImg, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    houghImg = np.zeros((roiImg.shape[0], roiImg.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(houghImg, lines)\n",
    "    if show:\n",
    "        houghImage = plt.figure()\n",
    "        plt.title('Hough Lines Img')\n",
    "        plt.imshow(houghImg)\n",
    "        houghImage.savefig('./HoughLines.jpg')\n",
    "    return houghImg, lines\n",
    "\n",
    "def findLeftAndRightLines(houghImg, lines, show=False):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "      houghImg, the first resultant from findHoughLines()\n",
    "      lines, the second resultant from findHoughLines()\n",
    "      show, plot the left and right lane lines\n",
    "    outputs:\n",
    "      leftBin, the lines that constitute the left lane line\n",
    "      rightBin, the lines that constitute the right lane line\n",
    "    \"\"\"\n",
    "    xSize = houghImg.shape[1]\n",
    "    ySize = houghImg.shape[0]\n",
    "    leftBin = np.array([[0, ySize, 0, ySize]])\n",
    "    rightBin = np.array([[xSize,ySize,xSize,ySize]])\n",
    "    leftOrigins = []\n",
    "    rightOrigins = []\n",
    "        \n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.legend()\n",
    "        \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            lineInfo = linregress([x1, x2], [y1, y2])\n",
    "            if lineInfo.slope == 0:\n",
    "                continue\n",
    "            elif abs(lineInfo.slope) >= np.pi/6 and (x1 <= xSize/2 and x2 <= xSize/2):\n",
    "                if show:\n",
    "                    plt.plot([x1, x2], [-y1, -y2], 'b')\n",
    "                leftBin = np.append(leftBin, line, axis=0)\n",
    "                leftOrigins = np.append(leftOrigins, ((ySize - lineInfo.intercept) / lineInfo.slope))\n",
    "            elif abs(lineInfo.slope) >= np.pi/6 and (x1 > xSize/2 and x2 > xSize/2) :\n",
    "                if show:\n",
    "                    plt.plot([x1, x2], [-y1, -y2], 'r')\n",
    "                rightBin = np.append(rightBin, line, axis=0)\n",
    "                rightOrigins = np.append(rightOrigins, ((ySize - lineInfo.intercept) / lineInfo.slope))\n",
    "\n",
    "    leftOrigin = np.median(leftOrigins)\n",
    "    rightOrigin = np.median(rightOrigins)\n",
    "    \n",
    "    # sort the bins into tidy arrays\n",
    "    leftBin[0,0] = leftBin[0,-2] = leftOrigin\n",
    "    rightBin[0,0] = rightBin[0,-2] = rightOrigin\n",
    "    \n",
    "    leftVerts = np.array([leftBin[0, 0:2]])\n",
    "    leftVerts = np.append(leftVerts, leftBin[1:, 0:2], axis=0)\n",
    "    leftVerts = np.append(leftVerts, leftBin[:, 2:], axis=0)\n",
    "\n",
    "    rightVerts = np.array([rightBin[0, 0:2]])\n",
    "    rightVerts = np.append(rightVerts, rightBin[1:, 0:2], axis=0)\n",
    "    rightVerts = np.append(rightVerts, rightBin[:, 2:], axis=0)\n",
    "    \n",
    "    if show:\n",
    "        plt.title('Left and Right Lane Lines')\n",
    "        plt.legend()\n",
    "        plt.savefig('./LeftRightLanes.jpg')\n",
    "        plt.show()\n",
    "           \n",
    "    return leftVerts, rightVerts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7184dfb70627>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mobjPts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgPts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindObjectPtsAndImgPts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjPts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgPts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./camera_cal/calibration*.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-23fab32bbc05>\u001b[0m in \u001b[0;36mcalibrateCamera\u001b[0;34m(objPoints, imgPoints, pathToImg, verbose)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# transVects, translational vecotrs to get camera position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcameraMtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistortCoeffs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotVects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransVects\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjPoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgPoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "objPts, imgPts = findObjectPtsAndImgPts()\n",
    "_ = calibrateCamera(objPts, imgPts, './camera_cal/calibration*.jpg', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "images = glob.glob('./test_images/test[3-5].jpg')\n",
    "\n",
    "for file in images:\n",
    "    combined_binary = createBinary(file, (170,255), (20,100), False)\n",
    "    roiImg = roiMask(combined_binary, False)\n",
    "    \n",
    "#     show=True\n",
    "#     rho=1\n",
    "#     theta=(np.pi/360)\n",
    "#     threshold=15\n",
    "#     min_line_len=50 \n",
    "#     max_line_gap=10\n",
    "#     houghImg, lines = findHoughLines(roiImg, show, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "#     leftVerts, rightVerts = findLeftAndRightLines(houghImg, lines, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
