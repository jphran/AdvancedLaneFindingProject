{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "    - Done\n",
    "* Apply a distortion correction to raw images.\n",
    "    - Done\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "    - Done\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "### PREVIOUS FNS ###\n",
    "# Condensed functions\n",
    "def weighted_img(img, initial_img, alpha=0.8, beta=1., gamma=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * alpa + img * beta + gamma\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, alpha, img, beta, gamma)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    `vertices` should be a numpy array of integer points.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def performGaussianBlur(origImg, show=False, kernelSize=9):\n",
    "    \"\"\" \n",
    "    inputs: \n",
    "      origImg, the original image read with matplotlib.image.imread\n",
    "      kernelSize, the number of pixels to blur\n",
    "      show, plot the blurred image\n",
    "    outputs:\n",
    "      blurImg, the resultant image\n",
    "    \"\"\"\n",
    "    blurImg = cv2.GaussianBlur(origImg, (kernelSize, kernelSize), 0)\n",
    "    if show:\n",
    "        blurImage = plt.figure()\n",
    "        plt.title('Gaussian Blur Img')\n",
    "        plt.imshow(blurImg)\n",
    "        blurImage.savefig('./blurImage.jpg')\n",
    "    return blurImg\n",
    "\n",
    "def performCannyEdgeDetection(blurImg, show=False, lowThres=65, highThres=120): #lowThres=60, highThres=120):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      blurImg, the result from performGaussianBlur()\n",
    "      lowThres, the rejection limit for pixel gradient\n",
    "      highThres, the minimum for pixel gradient (everything between low and high is included if connected to a highThreshold pixel)\n",
    "      show, plot the canny image\n",
    "    outputs:\n",
    "      cannyImg, the resultant image\n",
    "    \"\"\"\n",
    "    cannyImg = cv2.Canny(blurImg, lowThres, highThres)\n",
    "    if show:\n",
    "        cannyImage = plt.figure()\n",
    "        plt.title('Canny Edge Detect Color Img')\n",
    "        plt.imshow(cannyImg)\n",
    "        cannyImage.savefig('./cannyImg.jpg')\n",
    "    return cannyImg\n",
    "\n",
    "def performROIMasking(cannyImg, show=False):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "      cannyImg, the result from performCannyEdgeDetection()\n",
    "      show, plot the roi masked image\n",
    "    outputs:\n",
    "      roiImg, the resultant image\n",
    "    \"\"\"\n",
    "    xSize = cannyImg.shape[1]\n",
    "    ySize = cannyImg.shape[0]\n",
    "    \n",
    "    # mask inside of lane\n",
    "    roiInside = np.array([[(0,ySize),(xSize *(1/4), ySize),(xSize / 2, ySize * (2 / 3)),(xSize * (3/4),ySize),(xSize,ySize),(xSize,0),(0,0)]], dtype=np.int32)\n",
    "    roiImg = region_of_interest(cannyImg, roiInside)\n",
    "    \n",
    "    # mask outside of lane\n",
    "    roi = np.array([[(0, ySize), (xSize, ySize), (xSize / 2 + (xSize / 20), ySize / 2 + (ySize / 10)), (xSize / 2 - (xSize / 20), ySize / 2 + (ySize / 10))]], dtype=np.int32)\n",
    "    roiImg = region_of_interest(roiImg, roi) # create empty mask, fill polygon in mask, bitwise and the mask and img\n",
    "    \n",
    "    if show:\n",
    "        roiImage = plt.figure()\n",
    "        plt.title('ROI Mask')\n",
    "        plt.imshow(roiImg, cmap='gray')\n",
    "        roiImage.savefig('./roiImg.jpg')\n",
    "    return roiImg\n",
    "\n",
    "def findHoughLines(roiImg, show=False, rho=1, theta=(np.pi/360), threshold=15, min_line_len=12, max_line_gap=10):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      roiImg, the result from performROIMasking()\n",
    "      rho, the length resolution in a mesh unit [pixel]\n",
    "      theta, the angular resolution of the mesh [radians]\n",
    "      threshold, min number of votes for line detection\n",
    "      min_line_len, [pixels]\n",
    "      max_line_gap, [pixels]\n",
    "      show, plot the hough line image\n",
    "    outputs:\n",
    "      houghImg, the resultant image\n",
    "      lines, the resultant hough lines\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(roiImg, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    houghImg = np.zeros((roiImg.shape[0], roiImg.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(houghImg, lines)\n",
    "    if show:\n",
    "        houghImage = plt.figure()\n",
    "        plt.title('Hough Lines Img')\n",
    "        plt.imshow(houghImg)\n",
    "        houghImage.savefig('./HoughLines.jpg')\n",
    "    return houghImg, lines\n",
    "\n",
    "def findLeftAndRightLines(houghImg, lines, show=False):\n",
    "    \"\"\"\n",
    "    inputs: \n",
    "      houghImg, the first resultant from findHoughLines()\n",
    "      lines, the second resultant from findHoughLines()\n",
    "      show, plot the left and right lane lines\n",
    "    outputs:\n",
    "      leftBin, the lines that constitute the left lane line\n",
    "      rightBin, the lines that constitute the right lane line\n",
    "    \"\"\"\n",
    "    xSize = houghImg.shape[1]\n",
    "    ySize = houghImg.shape[0]\n",
    "    leftBin = np.array([[0, ySize, 0, ySize]])\n",
    "    rightBin = np.array([[xSize,ySize,xSize,ySize]])\n",
    "    leftOrigins = []\n",
    "    rightOrigins = []\n",
    "        \n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.legend()\n",
    "        \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            lineInfo = linregress([x1, x2], [y1, y2])\n",
    "            if lineInfo.slope == 0:\n",
    "                continue\n",
    "            elif abs(lineInfo.slope) >= np.pi/6 and (x1 <= xSize/2 and x2 <= xSize/2):\n",
    "                if show:\n",
    "                    plt.plot([x1, x2], [-y1, -y2], 'b')\n",
    "                leftBin = np.append(leftBin, line, axis=0)\n",
    "                leftOrigins = np.append(leftOrigins, ((ySize - lineInfo.intercept) / lineInfo.slope))\n",
    "            elif abs(lineInfo.slope) >= np.pi/6 and (x1 > xSize/2 and x2 > xSize/2) :\n",
    "                if show:\n",
    "                    plt.plot([x1, x2], [-y1, -y2], 'r')\n",
    "                rightBin = np.append(rightBin, line, axis=0)\n",
    "                rightOrigins = np.append(rightOrigins, ((ySize - lineInfo.intercept) / lineInfo.slope))\n",
    "\n",
    "    leftOrigin = np.median(leftOrigins)\n",
    "    rightOrigin = np.median(rightOrigins)\n",
    "    \n",
    "    # sort the bins into tidy arrays\n",
    "    leftBin[0,0] = leftBin[0,-2] = leftOrigin\n",
    "    rightBin[0,0] = rightBin[0,-2] = rightOrigin\n",
    "    \n",
    "    leftVerts = np.array([leftBin[0, 0:2]])\n",
    "    leftVerts = np.append(leftVerts, leftBin[1:, 0:2], axis=0)\n",
    "    leftVerts = np.append(leftVerts, leftBin[:, 2:], axis=0)\n",
    "\n",
    "    rightVerts = np.array([rightBin[0, 0:2]])\n",
    "    rightVerts = np.append(rightVerts, rightBin[1:, 0:2], axis=0)\n",
    "    rightVerts = np.append(rightVerts, rightBin[:, 2:], axis=0)\n",
    "    \n",
    "    if show:\n",
    "        plt.title('Left and Right Lane Lines')\n",
    "        plt.legend()\n",
    "        plt.savefig('./LeftRightLanes.jpg')\n",
    "        plt.show()\n",
    "           \n",
    "    return leftVerts, rightVerts \n",
    "    \n",
    "def drawGuideLines(origImg, lines, show=False):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "      leftBin, first resultant from findLeftAndRightLines()\n",
    "      rightBin, first resultant from findLeftAndRightLines()\n",
    "      show, plot final image with guide lines\n",
    "    outputs:\n",
    "      finalImg, the resultant image with guide lines\n",
    "    \"\"\"\n",
    "    guideImg = np.zeros_like(origImg)\n",
    "    \n",
    "    # find the longest line\n",
    "    longestLineYMax = np.shape(origImg)[1]\n",
    "    for line in lines:\n",
    "        if min(line[:,1]) < longestLineYMax:\n",
    "            longestLineYMax = min(line[:,1])\n",
    "    \n",
    "    # smooth lines\n",
    "    for idx, line in enumerate(lines):\n",
    "        pf = np.polyfit(line[:,0], line[:,1], 1)\n",
    "\n",
    "        # find x value needed to get max y value\n",
    "        pToSolve = np.copy(pf)\n",
    "        pToSolve[-1] = pToSolve[-1] - longestLineYMax\n",
    "        roots = np.roots(pToSolve)\n",
    "        p = np.poly1d(pf)\n",
    "\n",
    "        # extend the line if applicable\n",
    "        if p(roots[-1]) < min(line[:,1] - 1):\n",
    "            if idx == 0:\n",
    "                x = np.array(np.linspace(min(line[:,0]), roots[-1]), dtype='int') #needs to be int for opencv.line()\n",
    "            else:\n",
    "                x = np.array(np.linspace(roots[-1], max(line[:,0])), dtype='int') #needs to be int for opencv.line()\n",
    "        else:\n",
    "            x = np.array(np.linspace(min(line[:,0]), max(line[:,0])), dtype='int') #needs to be int for opencv.line()\n",
    "        \n",
    "        y = np.array(p(x), dtype='int')\n",
    "\n",
    "        for i in range(len(x) - 1):\n",
    "            cv2.line(guideImg, (x[i], y[i]), (x[i+1], y[i+1]), [255, 0, 0], 10)\n",
    "            \n",
    "    finalImg = weighted_img(guideImg, origImg)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure()\n",
    "        plt.imshow(finalImg)\n",
    "        plt.title('Final Guided Img')\n",
    "        plt.savefig('./FinalGuideImg.jpg')\n",
    "        plt.show()\n",
    "        \n",
    "    return finalImg\n",
    "\n",
    "# TODO\n",
    "def filter_lane_lines():\n",
    "    return\n",
    "\n",
    "def process_image(origImg):\n",
    "    verbose = False\n",
    "    blurImg = performGaussianBlur(origImg, verbose)\n",
    "    cannyImg = performCannyEdgeDetection(blurImg, verbose)\n",
    "    roiImg = performROIMasking(cannyImg, verbose)\n",
    "    houghImg, lines = findHoughLines(roiImg, verbose)    \n",
    "    leftBin, rightBin = findLeftAndRightLines(houghImg, lines, verbose)\n",
    "    processedImg = drawGuideLines(origImg, [leftBin, rightBin], verbose)\n",
    "\n",
    "    return processedImg\n",
    "\n",
    "### END PREV FNS ###\n",
    "\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # Pass in your image into this function\n",
    "    # Write code to do the following steps\n",
    "    # 1) Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # 2) Convert to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # 3) Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    # 4) If corners found: \n",
    "    if ret:\n",
    "        # a) draw corners\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        # b) define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "        srcPts = np.float32([corners[0], corners[nx - 1], corners[-1], corners[-nx]])\n",
    "             #Note: you could pick any four of the detected corners \n",
    "             # as long as those four corners define a rectangle\n",
    "             #One especially smart way to do this would be to use four well-chosen\n",
    "             # corners that were automatically detected during the undistortion steps\n",
    "             #We recommend using the automatic detection of corners in your code\n",
    "        # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "        dstPtsOffset = 100 # pixels, NOTE: arbitrary\n",
    "        origShape = (gray.shape[1], gray.shape[0])\n",
    "        dstPts = np.float32([[dstPtsOffset, dstPtsOffset], \n",
    "                                [origShape[0] - dstPtsOffset, dstPtsOffset], \n",
    "                                [origShape[0] - dstPtsOffset, origShape[1] - dstPtsOffset],\n",
    "                                [dstPtsOffset, origShape[1] - dstPtsOffset]])\n",
    "        # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        M = cv2.getPerspectiveTransform(srcPts, dstPts)\n",
    "        # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "        warped = cv2.warpPerspective(undist, M, origShape, flags=cv2.INTER_LINEAR)\n",
    "    return warped, M\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, np.int(orient == 'x'), np.int(orient == 'y'))\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    absSobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaledSobel = np.uint8(255 * absSobel / np.max(absSobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    sobelBinary = np.zeros_like(scaledSobel)\n",
    "    sobelBinary[(scaledSobel >= thresh_min) & (scaledSobel <= thresh_max)] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    binary_output = sobelBinary\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "nx = 9\n",
    "ny = 6\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        # Draw\n",
    "        img = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort image\n",
    "ret, cameraMtx, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('../camera_cal/calibration*.jpg')\n",
    "\n",
    "# Draw\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    # 1) Undistort using mtx and dist\n",
    "    undist = cv2.undistort(img, cameraMtx, distCoeffs, None, cameraMtx)\n",
    "    # 2) Convert to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "    # 3) Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    # 4) If corners found: \n",
    "    if ret:\n",
    "        # a) draw corners\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        # b) define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "        srcPts = np.float32([corners[0], corners[nx - 1], corners[-1], corners[-nx]])\n",
    "        # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "        dstPtsOffset = 100 # pixels, NOTE: arbitrary\n",
    "        origShape = (gray.shape[1], gray.shape[0])\n",
    "        dstPts = np.float32([[dstPtsOffset, dstPtsOffset], \n",
    "                                [origShape[0] - dstPtsOffset, dstPtsOffset], \n",
    "                                [origShape[0] - dstPtsOffset, origShape[1] - dstPtsOffset],\n",
    "                                [dstPtsOffset, origShape[1] - dstPtsOffset]])\n",
    "        # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "        M = cv2.getPerspectiveTransform(srcPts, dstPts)\n",
    "        # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "        warped = cv2.warpPerspective(undist, M, origShape, flags=cv2.INTER_LINEAR)\n",
    "        cv2.imshow('img', warped)\n",
    "        cv2.waitKey(500)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Sobel Operator (gradient) and HLS colorspace thresholds \n",
    "\n",
    "image = cv2.imread('../test_images/test2.jpg')\n",
    "s_thresh=(170, 255) # color channel threshhold\n",
    "sx_thresh=(20, 100) # x gradient thresh hold\n",
    "\n",
    "img = np.copy(image)\n",
    "# Convert to HLS color space and separate the V channel\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "l_channel = hls[:,:,1]\n",
    "s_channel = hls[:,:,2]\n",
    "# Sobel x\n",
    "sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "# Threshold x gradient\n",
    "sxbinary = np.zeros_like(scaled_sobel)\n",
    "sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "\n",
    "# Threshold color channel\n",
    "s_binary = np.zeros_like(s_channel)\n",
    "s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "# Stack each channel\n",
    "color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "ax2.imshow(color_binary)\n",
    "ax2.set_title('Sobel X, and Color channel ', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warp the perspective to birds eye view\n",
    "xSize = img.shape()[1]\n",
    "ySize = img.shape()[0]\n",
    "\n",
    "srcPts = np.float32([(0,ySize), , corners[-1], corners[-nx]])\n",
    "\n",
    "# c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "dstPtsOffset = 100 # pixels, NOTE: arbitrary\n",
    "origShape = (gray.shape[1], gray.shape[0])\n",
    "dstPts = np.float32([[dstPtsOffset, dstPtsOffset], \n",
    "                        [origShape[0] - dstPtsOffset, dstPtsOffset], \n",
    "                        [origShape[0] - dstPtsOffset, origShape[1] - dstPtsOffset],\n",
    "                        [dstPtsOffset, origShape[1] - dstPtsOffset]])\n",
    "# d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "M = cv2.getPerspectiveTransform(srcPts, dstPts)\n",
    "# e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "warped = cv2.warpPerspective(undist, M, origShape, flags=cv2.INTER_LINEAR)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
